{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import related libraries\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vision_utils\n",
    "\n",
    "from models.srgan_discriminator import Discriminator\n",
    "from models.srgan_generator import Generator\n",
    "\n",
    "import os\n",
    "import tqdm\n",
    "import numpy\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "import cv2\n",
    "\n",
    "# constants\n",
    "learning_rate = 0.0002\n",
    "beta1_for_adam = 0.5\n",
    "beta2_for_adam = 0.999\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "length_of_z_input_vector = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and dataset initializing step\n",
    "def initial_weights(input_module):\n",
    "    class_name = input_module.__class__.__name__\n",
    "    if class_name.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(input_module.weight, 0.0, 0.02)\n",
    "    elif class_name.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(input_module.weight, 1.0, 0.02)\n",
    "        torch.nn.init.zeros_(input_module.bias)\n",
    "\n",
    "generator_discriminator_interface_size = 64\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "discriminator_object = Discriminator(3).to(device)\n",
    "generator_object = Generator(length_of_z_input_vector, 3).to(device)\n",
    "\n",
    "discriminator_object.apply(initial_weights)\n",
    "generator_object.apply(initial_weights)\n",
    "\n",
    "optimizer_for_discriminator = Adam(discriminator_object.parameters(), lr=learning_rate, betas=(beta1_for_adam, beta2_for_adam))\n",
    "optimizer_for_generator = Adam(generator_object.parameters(), lr=learning_rate, betas=(beta1_for_adam, beta2_for_adam))\n",
    "\n",
    "loss_for_discriminator = torch.nn.BCELoss()\n",
    "\n",
    "tensored_data_set = dataset.ImageFolder(root='/workspace', transform=transforms.Compose([transforms.Resize(generator_discriminator_interface_size), transforms.CenterCrop(generator_discriminator_interface_size), transforms.ToTensor(),\n",
    "# transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "]))\n",
    "\n",
    "loaded_data_set = DataLoader(tensored_data_set, shuffle=True, num_workers=10)\n",
    "\n",
    "fixed_noise = torch.randn(generator_discriminator_interface_size, length_of_z_input_vector, 1, 1, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train both models\n",
    "for epoch in range(501):\n",
    "    for index, data in enumerate(loaded_data_set, 0):\n",
    "        # update discriminator network\n",
    "        ## training with real data\n",
    "        discriminator_object.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, dtype=real_cpu.dtype, device=device)\n",
    "\n",
    "        output = discriminator_object(real_cpu).view(-1)\n",
    "        loss = loss_for_discriminator(output, label)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        ## training with fake data\n",
    "        noise = torch.randn(batch_size, length_of_z_input_vector, 1, 1, device=device)\n",
    "        fake = generator_object(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = discriminator_object(fake.detach())\n",
    "        \n",
    "        loss2 = loss_for_discriminator(output, label)\n",
    "        loss2.backward()\n",
    "\n",
    "        optimizer_for_discriminator.step()\n",
    "\n",
    "\n",
    "        # update generator network\n",
    "        generator_object.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        output = discriminator_object(fake).view(-1) # use previous data\n",
    "        \n",
    "        loss3 = loss_for_discriminator(output, label)\n",
    "        loss3.backward()\n",
    "\n",
    "        optimizer_for_generator.step()\n",
    "\n",
    "        if index % 100 == 0:\n",
    "            vision_utils.save_image(real_cpu, '/data/home/taeho/pytorch_tutorials/samples_epoch%03d.png' % (epoch), normalize=True)\n",
    "            fake = generator_object(fixed_noise)\n",
    "            plot.figure(figsize=(8,8))\n",
    "            plot.axis(\"off\")\n",
    "            plot.title(\"Training Images\")\n",
    "            plot.imshow(numpy.transpose(vision_utils.make_grid(fake.detach(), padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "            vision_utils.save_image(fake.detach(), '/data/home/taeho/pytorch_tutorials/fake_samples_epoch%03d.png' % (epoch), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weight models\n",
    "torch.save(discriminator_object.state_dict(), '/data/home/taeho/pytorch_tutorials/srgan_discriminator_weight')\n",
    "torch.save(generator_object.state_dict(), '/data/home/taeho/pytorch_tutorials/srgan_generator_weight')"
   ]
  }
 ]
}